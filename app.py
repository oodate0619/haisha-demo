import streamlit as st
import pandas as pd
import json
import random

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIé…è»Šã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ - ãƒ‡ãƒ¢", layout="wide")

st.title("ğŸš› é…è»Šæœ€é©åŒ–AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ (Prototype)")
st.markdown("""
ã“ã®ãƒ‡ãƒ¢ã¯ã€**ã€Œãƒ™ãƒ†ãƒ©ãƒ³é…è»Šæ‹…å½“è€…ã®é ­ã®ä¸­ï¼ˆåˆ¤æ–­ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ã€**ã‚’AIã«ç§»æ¤ã—ã€
è‡ªç„¶è¨€èªã®æŒ‡ç¤ºã§æœ€é©ãªãƒ«ãƒ¼ãƒˆçµ„ã¿ã‚’ææ¡ˆã•ã›ã‚‹ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã§ã™ã€‚
""")

# --- 1. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ (æ¶ç©ºãƒ‡ãƒ¼ã‚¿ã®æº–å‚™) ---
def generate_dummy_data():
    # ç¤¾å“¡ãƒ‡ãƒ¼ã‚¿
    staff_data = [
        {"åå‰": "ä½è—¤(A)", "ã‚¹ã‚­ãƒ«": "ãƒ™ãƒ†ãƒ©ãƒ³", "æ€§æ ¼": "æ…é‡ãƒ»ç¢ºå®Ÿ", "è‹¦æ‰‹": "ç‰¹ã«ãªã—", "å¸Œæœ›": "ä»¶æ•°ã‚’ç¨¼ããŸã„"},
        {"åå‰": "éˆ´æœ¨(B)", "ã‚¹ã‚­ãƒ«": "ä¸­å …", "æ€§æ ¼": "ç¤¾äº¤çš„", "è‹¦æ‰‹": "äº‹å‹™ä½œæ¥­", "å¸Œæœ›": "é è·é›¢ã¯é¿ã‘ãŸã„"},
        {"åå‰": "ç”°ä¸­(C)", "ã‚¹ã‚­ãƒ«": "æ–°äºº", "æ€§æ ¼": "å†…å‘çš„", "è‹¦æ‰‹": "å³ã—ã„ç®¡ç†äºº", "å¸Œæœ›": "ãƒ¡ãƒ³ã‚¿ãƒ¼åŒè¡Œå¸Œæœ›"}
    ]
    
    # ç¾å ´ãƒ‡ãƒ¼ã‚¿
    locations = ["é’è‘‰åŒºãƒãƒ³ã‚·ãƒ§ãƒ³", "ä¸­å¤®ãƒ“ãƒ«", "æ¸¯åŒ—å€‰åº«", "ç·‘åŒºå½¹æ‰€", "å—ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«"]
    difficulties = ["ä½", "ä¸­", "é«˜(è¦äº¤æ¸‰)"]
    stress_levels = ["æ™®é€š", "é«˜ã„(ç®¡ç†äººãŒå³ã—ã„)", "ä½ã„"]
    
    site_data = []
    for loc in locations:
        site_data.append({
            "ç¾å ´å": loc,
            "ä½œæ¥­é›£æ˜“åº¦": random.choice(difficulties),
            "å¯¾äººã‚¹ãƒˆãƒ¬ã‚¹": random.choice(stress_levels),
            "æ‰€è¦æ™‚é–“(åˆ†)": random.choice([30, 60, 90, 120])
        })
    
    return pd.DataFrame(staff_data), pd.DataFrame(site_data)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
if 'df_staff' not in st.session_state:
    st.session_state.df_staff, st.session_state.df_site = generate_dummy_data()

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ‡ãƒ¼ã‚¿ç¢ºèªã¨è¨­å®š ---
with st.sidebar:
    st.header("ğŸ› ï¸ è¨­å®šãƒ»ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
    openai_api_key = st.text_input("OpenAI API Key (æœªå…¥åŠ›ãªã‚‰æ¨¡æ“¬ãƒ¢ãƒ¼ãƒ‰)", type="password")
    
    st.subheader("ğŸ“‹ ç¾åœ¨ã®è¦å“¡ãƒªã‚¹ãƒˆ")
    st.dataframe(st.session_state.df_staff, hide_index=True)
    
    st.subheader("ğŸ“ ä»Šæ—¥ã®ç¾å ´ãƒªã‚¹ãƒˆ")
    st.dataframe(st.session_state.df_site, hide_index=True)
    
    if st.button("ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿæˆã™ã‚‹"):
        st.session_state.df_staff, st.session_state.df_site = generate_dummy_data()
        st.rerun()

# --- 2. AIãƒ­ã‚¸ãƒƒã‚¯å®šç¾© (ã“ã“ãŒã€Œãƒ™ãƒ†ãƒ©ãƒ³ã®è„³å†…ã€) ---
def get_ai_response(user_instruction, df_staff, df_site, api_key):
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ†ã‚­ã‚¹ãƒˆ(JSON/CSV)ã«å¤‰æ›ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸ‹ã‚è¾¼ã‚€
    staff_text = df_staff.to_json(orient="records", force_ascii=False)
    site_text = df_site.to_json(orient="records", force_ascii=False)

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼šãƒ™ãƒ†ãƒ©ãƒ³é…è»Šä¿‚ã®å½¹å‰²å®šç¾©
    system_prompt = f"""
    ã‚ãªãŸã¯ç†Ÿç·´ã®é…è»Šæ‹…å½“è€…ã§ã™ã€‚ä»¥ä¸‹ã®ã€Œç¤¾å“¡ãƒ‡ãƒ¼ã‚¿ã€ã¨ã€Œç¾å ´ãƒ‡ãƒ¼ã‚¿ã€ã‚’ã‚‚ã¨ã«ã€
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«å¾“ã£ã¦æœ€é©ãªäººå“¡é…ç½®ï¼ˆãƒ«ãƒ¼ãƒˆçµ„ã¿ï¼‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
    
    # åˆ¤æ–­åŸºæº–
    1. æ–°äººã‚„å†…å‘çš„ãªç¤¾å“¡ã«ã¯ã€Œå¯¾äººã‚¹ãƒˆãƒ¬ã‚¹ã€ãŒé«˜ã„ç¾å ´ï¼ˆç®¡ç†äººãŒå³ã—ã„ç­‰ï¼‰ã‚’é¿ã‘ã‚‹ã€‚
    2. ãƒ™ãƒ†ãƒ©ãƒ³ã«ã¯é›£æ˜“åº¦ãŒé«˜ã„ç¾å ´ã‚„ã€ä»¶æ•°ã‚’å¤šãå‰²ã‚Šå½“ã¦ã‚‹ã€‚
    3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ç‰¹è¨˜äº‹é …ï¼ˆä½“èª¿ä¸è‰¯ãªã©ï¼‰ã‚’æœ€å„ªå…ˆã™ã‚‹ã€‚
    
    # å‡ºåŠ›å½¢å¼
    ææ¡ˆã¯ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¡Œã£ã¦ãã ã•ã„ã€‚
    - **é…ç½®æ¡ˆã®æ¦‚è¦**: ãªãœã“ã®é…ç½®ã«ã—ãŸã‹ã®å…¨ä½“çš„ãªç†ç”±
    - **å€‹åˆ¥å‰²ã‚Šå½“ã¦**:
      - [ç¤¾å“¡å]: [æ‹…å½“ç¾å ´å] (ç†ç”±: ...)
    
    # ãƒ‡ãƒ¼ã‚¿
    [ç¤¾å“¡ãƒªã‚¹ãƒˆ]: {staff_text}
    [ç¾å ´ãƒªã‚¹ãƒˆ]: {site_text}
    """

    if not api_key:
        # APIã‚­ãƒ¼ãŒãªã„å ´åˆã®æ¨¡æ“¬ãƒ¬ã‚¹ãƒãƒ³ã‚¹ (Mock)
        import time
        time.sleep(2) # æ€è€ƒæ™‚é–“ã‚’æ¼”å‡º
        return f"""
**(æ¨¡æ“¬ãƒ¢ãƒ¼ãƒ‰ã§ã®å›ç­”ã§ã™)**
æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚ã”æŒ‡ç¤ºã®ã€Œ{user_instruction}ã€ã‚’è€ƒæ…®ã—ã€ä»¥ä¸‹ã®é…ç½®ã‚’ææ¡ˆã—ã¾ã™ã€‚

**é…ç½®æ¡ˆã®æ¦‚è¦:**
{user_instruction[:10]}... ã¨ã„ã†ç‚¹ã‚’é‡è¦–ã—ã€ç”°ä¸­(C)ã•ã‚“ã«ã¯å¿ƒç†çš„è² æ‹…ã®å°‘ãªã„ç¾å ´ã‚’ã€ä½è—¤(A)ã•ã‚“ã«ã¯é›£æ‰€ã‚’ä»»ã›ã‚‹æ§‹æˆã«ã—ã¾ã—ãŸã€‚

**å€‹åˆ¥å‰²ã‚Šå½“ã¦:**
* **ä½è—¤(A)**: ä¸­å¤®ãƒ“ãƒ«ã€ç·‘åŒºå½¹æ‰€
    * *ç†ç”±*: é›£æ˜“åº¦ã€Œé«˜ã€ã®ç¾å ´ã§ã™ãŒã€ãƒ™ãƒ†ãƒ©ãƒ³ã®ä½è—¤ã•ã‚“ãªã‚‰ç¢ºå®Ÿã«å¯¾å¿œå¯èƒ½ã§ã™ã€‚
* **éˆ´æœ¨(B)**: æ¸¯åŒ—å€‰åº«ã€å—ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«
    * *ç†ç”±*: ç§»å‹•è·é›¢ã‚’è€ƒæ…®ã—ã€è¿‘éš£ã‚¨ãƒªã‚¢ã§ã¾ã¨ã‚ã¾ã—ãŸã€‚
* **ç”°ä¸­(C)**: é’è‘‰åŒºãƒãƒ³ã‚·ãƒ§ãƒ³
    * *ç†ç”±*: å†…å‘çš„ãªæ€§æ ¼ã‚’è€ƒæ…®ã—ã€å¯¾äººã‚¹ãƒˆãƒ¬ã‚¹ãŒã€Œä½ã„ã€ç¾å ´ã‚’é¸å®šã—ã¾ã—ãŸã€‚æŒ‡ç¤ºé€šã‚Šç„¡ç†ã®ãªã„é…ç½®ã§ã™ã€‚
        """
    
    else:
        # å®Ÿéš›ã«OpenAI APIã‚’å©ã
        try:
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo", # ã‚³ã‚¹ãƒˆé‡è¦–ã§3.5ã€ç²¾åº¦é‡è¦–ãªã‚‰gpt-4
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_instruction}
                ],
                temperature=0.7,
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# --- 3. ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ---
st.subheader("ğŸ’¬ AIé…è»Šã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¸ã®æŒ‡ç¤º")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚æœ¬æ—¥ã®é…ç½®ã¯ã©ã†ã—ã¾ã™ã‹ï¼Ÿã€Œç”°ä¸­ã•ã‚“ã¯ä»Šæ—¥ãƒ¡ãƒ³ã‚¿ãƒ«ä¸èª¿ãªã®ã§å„ªã—ã‚ã§ã€ã®ã‚ˆã†ã«æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚"}]

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    # AIã®æ€è€ƒä¸­è¡¨ç¤º
    with st.chat_message("assistant"):
        with st.spinner("ãƒ™ãƒ†ãƒ©ãƒ³ã®æ€è€ƒãƒ­ã‚¸ãƒƒã‚¯ã§æ¤œè¨ä¸­..."):
            response = get_ai_response(
                prompt, 
                st.session_state.df_staff, 
                st.session_state.df_site, 
                openai_api_key
            )
            st.write(response)
            
            # ã€Œè£å´ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚’è¦‹ã›ã‚‹ï¼ˆãƒ‡ãƒ¢åŠ¹æœç”¨ï¼‰
            with st.expander("ğŸ‘€ AIãŒè¦‹ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨æŒ‡ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸­èº«ï¼‰"):
                st.code(f"User Instruction: {prompt}\n\nData Context Used:\nStaff: {len(st.session_state.df_staff)} records\nSites: {len(st.session_state.df_site)} records", language="yaml")
    
    st.session_state.messages.append({"role": "assistant", "content": response})